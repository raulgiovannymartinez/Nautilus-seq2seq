{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "K4XWHTiPlAAK"
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils import data\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import join, abspath\n",
    "import itertools\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "from torch.autograd import Variable\n",
    "from scipy.signal import tukey\n",
    "from torch.utils import data\n",
    "from tqdm.notebook import tqdm\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import json\n",
    "import sqlalchemy as sal\n",
    "import getpass\n",
    "import pandas as pd\n",
    "from urllib.request import urlopen\n",
    "import pickle as pkl\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Saved Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = '../data_traffic/traffic_bayArea_station_mediumSize_12pts.pkl'\n",
    "# filename = '../data_traffic/traffic_bayArea_station_400001.pkl'\n",
    "# filename = '../data_traffic/traffic_bayArea_station_allStations_12pts_withNaNs.pkl'\n",
    "filename = r'C:\\Users\\rmartinez4\\Box\\Personal Git\\dse-capstone\\seq2seq_example\\data_traffic\\traffic_bayArea_station_allStations_12pts_SPEED.pkl'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i6Cf8NtglAAT",
    "outputId": "a5776fb4-df01-4502-d0b4-921ed6541ecf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# read tensor\n",
    "with open(filename, \"rb\") as fout:\n",
    "    c_time_series = pkl.load(fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "GeGqqaF3lAAT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16618280, 24, 1])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_time_series.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kPCU3aA5lAAU"
   },
   "source": [
    "# Generate Train and Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "zVxgdjvylAAU"
   },
   "outputs": [],
   "source": [
    "def scale_data(data_x, data_y, out_pos = 0, return_current_avg_std = False):\n",
    "    \"\"\" \n",
    "    Arg:\n",
    "        data_x: features\n",
    "        data_y: labels\n",
    "        out_pos: the position of feature of which average and stand deviation will be returned.\n",
    "    returns:\n",
    "        1. Normalized features and labels\n",
    "        2. Average and standard deviation of the selected feature.\n",
    "    \"\"\"\n",
    "    avg = data_x[:,:,out_pos].mean()\n",
    "    std = data_x[:,:,out_pos].std()\n",
    "#     c_avg = data_x[:,:,1].mean()\n",
    "#     c_std = data_x[:,:,1].std()\n",
    "    for i in range(data_x.shape[-1]):\n",
    "        data_x[:,:,i] = (data_x[:,:,i] - data_x[:,:,i].mean())/data_x[:,:,i].std()\n",
    "    data_y = (data_y-avg)/std\n",
    "    if return_current_avg_std:\n",
    "        return data_x, data_y, (avg, std)  \n",
    "#         return data_x, data_y, (avg, std), (c_avg, c_std)   \n",
    "    else:\n",
    "        return data_x, data_y, (avg, std)\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, X, Y, lst_index, output_steps, position_embedding = (False)):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            lst_index: indexes of observations in the dataset.\n",
    "            output_steps: Forecasting Horizon.\n",
    "        \"\"\"\n",
    "        self.X = X[lst_index]\n",
    "        self.Y = Y[lst_index]\n",
    "        self.output_steps = output_steps\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.X[index]\n",
    "        y = self.Y[index][:self.output_steps]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w0yv7iQtlAAU",
    "outputId": "f50267a3-3788-46ae-a11b-4ac3628d6e57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "sample_size = c_time_series.shape[0]\n",
    "segment_size = c_time_series.shape[1]\n",
    "pred_size = int(segment_size/2)\n",
    "\n",
    "test_size = sample_size // 4\n",
    "train_valid_size = test_size * 3\n",
    "training_size = test_size * 2\n",
    "validation_size = test_size * 1\n",
    "\n",
    "# X_train = c_time_series[:train_valid_size,:pred_size,:]\n",
    "# Y_train = c_time_series[:train_valid_size,pred_size:,:]\n",
    "# sample_size, pred_length, feature_count = X_train.shape\n",
    "\n",
    "X_test = c_time_series[training_size:training_size+test_size,:pred_size,:]\n",
    "Y_test = c_time_series[training_size:training_size+test_size,pred_size:,:]\n",
    "\n",
    "X_all = c_time_series[:train_valid_size+test_size,:pred_size,:]\n",
    "Y_all = c_time_series[:train_valid_size+test_size,pred_size:,:]\n",
    "\n",
    "X, Y, (avg, std) = scale_data(X_all, Y_all, out_pos = 0, return_current_avg_std = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(64.3558, dtype=torch.float64)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_time_series.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-2.7682e-15, dtype=torch.float64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.mean()\n",
    "\n",
    "# data_x[:,:,i].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.1143e-14, dtype=torch.float64)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000, dtype=torch.float64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IjmIKWaclAAV",
    "outputId": "03bdf0e0-cd0f-4c07-a51d-e985b82e9315"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12463710, 12, 1]) torch.Size([12463710, 12, 1])\n",
      "torch.Size([4154570, 12, 1]) torch.Size([4154570, 12, 1])\n",
      "torch.Size([16618280, 12, 1]) torch.Size([16618280, 12, 1])\n",
      "4154570 12463710 8309140 4154570\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_test.shape, Y_test.shape)\n",
    "print(X_all.shape, Y_all.shape)\n",
    "\n",
    "# print(sample_size, pred_length, feature_count)\n",
    "\n",
    "print(test_size, train_valid_size, training_size, validation_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9102],\n",
       "        [0.8691],\n",
       "        [0.9650],\n",
       "        [0.9787],\n",
       "        [0.9513],\n",
       "        [0.9787],\n",
       "        [0.9376],\n",
       "        [0.9102],\n",
       "        [0.8691],\n",
       "        [0.8417],\n",
       "        [0.8417],\n",
       "        [0.8554]], dtype=torch.float64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "QJRsLnOMlAAV"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, dropout_rate):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_dim: the dimension of input sequences.\n",
    "            hidden_dim: number hidden units.\n",
    "            num_layers: number of encode layers.\n",
    "            dropout_rate: recurrent dropout rate.\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=num_layers, \n",
    "                            bidirectional = True, dropout = dropout_rate, batch_first = True)\n",
    "        \n",
    "    def forward(self, source):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            source: input tensor(batch_size*input dimension)\n",
    "        Return:\n",
    "            outputs: Prediction\n",
    "            concat_hidden: hidden states\n",
    "        \"\"\"\n",
    "        outputs, hidden = self.lstm(source)\n",
    "        return outputs, hidden\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, hidden_dim, num_layers, dropout_rate):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            output_dim: the dimension of output sequences.\n",
    "            hidden_dim: number hidden units.\n",
    "            num_layers: number of code layers.\n",
    "            dropout_rate: recurrent dropout rate.\n",
    "        \"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        # Since the encoder is bidirectional, decoder has double hidden size\n",
    "        self.lstm = nn.LSTM(output_dim, hidden_dim*2, num_layers = num_layers, \n",
    "                            dropout = dropout_rate, batch_first = True)\n",
    "        \n",
    "        self.out = nn.Linear(hidden_dim*2, output_dim)\n",
    "      \n",
    "    def forward(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: prediction from previous prediction.\n",
    "            hidden: hidden states from previous cell.\n",
    "        Returns:\n",
    "            1. prediction for current step.\n",
    "            2. hidden state pass to next cell.\n",
    "        \"\"\"\n",
    "        output, hidden = self.lstm(x, hidden)   \n",
    "        prediction = self.out(output.float())\n",
    "        return prediction, hidden     \n",
    "    \n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            encoder: Encoder object.\n",
    "            decoder: Decoder object.\n",
    "            device: \n",
    "        \"\"\"\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, source, target_tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            source: input tensor.\n",
    "            target_length: forecasting steps.\n",
    "        Returns:\n",
    "            total prediction\n",
    "        \"\"\"\n",
    "        batch_size = source.size(0) \n",
    "        input_length = source.size(1) \n",
    "        target_length = target_tensor.shape[1]\n",
    "        output_dim = target_tensor.shape[-1]\n",
    "        encoder_hidden = (torch.zeros(self.encoder.num_layers*2, batch_size, self.encoder.hidden_dim, device=device),\n",
    "                          torch.zeros(self.encoder.num_layers*2, batch_size, self.encoder.hidden_dim, device=device))\n",
    "        encoder_output, encoder_hidden = self.encoder(source)\n",
    "        \n",
    "        # Concatenate the hidden states of both directions.\n",
    "        num_layers = int(encoder_hidden[0].shape[0]/2)\n",
    "        h = torch.cat([encoder_hidden[0][0:self.encoder.num_layers,:,:], \n",
    "                       encoder_hidden[0][-self.encoder.num_layers:,:,:]], \n",
    "                      dim=2, out=None).to(device)\n",
    "        c = torch.cat([encoder_hidden[1][0:self.encoder.num_layers,:,:], \n",
    "                       encoder_hidden[1][-self.encoder.num_layers:,:,:]], \n",
    "                      dim=2, out=None).to(device)\n",
    "        concat_hidden = (h, c)\n",
    "        \n",
    "        \n",
    "        outputs = torch.zeros(batch_size, target_length, output_dim).to(self.device)\n",
    "        decoder_output = torch.zeros((batch_size, 1, output_dim), device = self.device)\n",
    "        decoder_hidden = concat_hidden\n",
    "        \n",
    "        for t in range(target_length):  \n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_output, decoder_hidden)\n",
    "            outputs[:,t:t+1,:] = decoder_output\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "PGK3TwahlAAW"
   },
   "outputs": [],
   "source": [
    "def run_epoch_train(model, data_generator, model_optimizer, criterion):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model: RNN model.\n",
    "        data_generator: data.DataLoader object.\n",
    "        model_optimizer: optimizer.\n",
    "        criterion: loss function\n",
    "    Returns:\n",
    "        Root Mean Square Error on Training Dataset\n",
    "    \"\"\"\n",
    "    MSE = []\n",
    "    for x, y in data_generator:\n",
    "        # The input shape for nn.conv1d should sequence_length * batch_size * #features\n",
    "        input_tensor, target_tensor = x.to(device).float(), y.to(device).float()\n",
    "        model_optimizer.zero_grad()\n",
    "        loss = 0\n",
    "        output = model(input_tensor, target_tensor).reshape(target_tensor.shape)\n",
    "        num_iter = output.size(0)\n",
    "        for ot in range(num_iter):\n",
    "            loss += criterion(output[ot], target_tensor[ot])\n",
    "        MSE.append(loss.item()/num_iter)\n",
    "        loss.backward()\n",
    "        model_optimizer.step()\n",
    "    \n",
    "    return round(np.sqrt(np.mean(MSE)), 5)\n",
    " \n",
    "\n",
    "def run_epoch_eval(model, data_generator, criterion, return_pred = False):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model: CNN model.\n",
    "        data_generator: data.DataLoader object.\n",
    "        criterion: loss function\n",
    "    Returns:\n",
    "        Root Mean Square Error on evaluation datasets.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        MSE = []\n",
    "        preds = []\n",
    "        for x, y in data_generator:\n",
    "            input_tensor, target_tensor = x.to(device).float(), y.to(device).float()\n",
    "            loss = 0\n",
    "            output = model(input_tensor, target_tensor).reshape(target_tensor.shape)\n",
    "            \n",
    "            preds.append(output.cpu().detach().numpy())\n",
    "            num_iter = output.size(0)\n",
    "            \n",
    "            for ot in range(num_iter):\n",
    "                loss += criterion(output[ot], target_tensor[ot])\n",
    "            MSE.append(loss.item()/num_iter)\n",
    "            \n",
    "    if return_pred == True:\n",
    "        preds =  np.concatenate(preds).squeeze(-1)\n",
    "        return round(np.sqrt(np.mean(MSE)), 5), preds\n",
    "    else:\n",
    "        return round(np.sqrt(np.mean(MSE)), 5)\n",
    "\n",
    "\n",
    "def train_model(model, X, Y, learning_rate, output_steps, batch_size, train_idx, valid_idx, test_idx, test=False, return_pred=False):\n",
    "    # Initialize the model and define optimizer, learning rate decay and criterion\n",
    "    optimizer = torch.optim.RMSprop(model.parameters(), lr = learning_rate)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size= 5, gamma=0.8)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # Split dataset into training set, validation set and test set.\n",
    "    train_rmse, train_set = [], Dataset(X, Y, train_idx, output_steps)\n",
    "    valid_rmse, valid_set = [], Dataset(X, Y, valid_idx, output_steps)\n",
    "    if test:\n",
    "        test_rmse, test_set = [], Dataset(X, Y, test_idx, output_steps)\n",
    "    \n",
    "    min_loss = 1000\n",
    "    best_model = 0\n",
    "    best_preds = 0\n",
    "    min_valid_loss = 1000\n",
    "    \n",
    "    for i in tqdm(range(200)):\n",
    "        start = time.time()\n",
    "        scheduler.step()\n",
    "        train_generator = data.DataLoader(train_set, batch_size = batch_size, shuffle = True)\n",
    "        valid_generator = data.DataLoader(valid_set, batch_size = batch_size, shuffle = False)\n",
    "        if test:\n",
    "            test_generator = data.DataLoader(test_set, batch_size = batch_size, shuffle = False)\n",
    " \n",
    "        model.train()\n",
    "        train_rmse.append(run_epoch_train(model, train_generator, optimizer, criterion))\n",
    "            \n",
    "        model.eval()\n",
    "        rmse, predictions = run_epoch_eval(model,  valid_generator, criterion, return_pred = True)\n",
    "        valid_rmse.append(rmse)\n",
    "        \n",
    "        if test:\n",
    "            if return_pred:\n",
    "                t_rmse, test_predictions = run_epoch_eval(model, test_generator, criterion, return_pred = True)\n",
    "            else:\n",
    "                t_rmse = run_epoch_eval(model, test_generator, criterion, return_pred = False)\n",
    "            test_rmse.append(t_rmse)\n",
    "        \n",
    "        if valid_rmse[-1] < min_loss:\n",
    "            min_loss = valid_rmse[-1]\n",
    "            best_model = model\n",
    "            min_valid_loss = valid_rmse[-1]\n",
    "            best_preds = predictions\n",
    "            min_valid_loss = valid_rmse[-1]\n",
    "            \n",
    "        if (len(train_rmse) > 15 and np.mean(valid_rmse[-5:]) >= np.mean(valid_rmse[-10:-5])):\n",
    "            break\n",
    "            \n",
    "    end = time.time()       \n",
    "    print((\"Epoch %d:\"%(i+1)), (\"Loss: %f; \"%train_rmse[-1]),(\"valid_loss: %f; \"%valid_rmse[-1]), \n",
    "          (\"Time: %f; \"%round(end - start,5)))\n",
    "\n",
    "    if test:\n",
    "        if return_pred:\n",
    "            return best_model, (train_rmse,valid_rmse),  best_preds, min_valid_loss, test_rmse, test_predictions\n",
    "        return best_model, (train_rmse,valid_rmse),  best_preds, min_valid_loss, test_rmse\n",
    "    return best_model, (train_rmse,valid_rmse),  best_preds, min_valid_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "dropout_rate = 0.2\n",
    "num_layers = 1\n",
    "hidden_dim = 64\n",
    "\n",
    "input_size = 1\n",
    "output_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 930 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "input_steps = segment_size\n",
    "output_steps = segment_size\n",
    "# input_size = 2\n",
    "\n",
    "train_idx = list(range(training_size))\n",
    "valid_idx = list(range(training_size, train_valid_size))\n",
    "test_idx = list(range(train_valid_size, train_valid_size + test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 26.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "encoder = Encoder(input_size, hidden_dim, num_layers, dropout_rate)\n",
    "decoder = Decoder(output_size, hidden_dim, num_layers, dropout_rate)\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (lstm): LSTM(1, 64, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (lstm): LSTM(1, 128, batch_first=True, dropout=0.2)\n",
       "    (out): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101505"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print number of parameters for the model\n",
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 82,
     "referenced_widgets": [
      "86efb748af4d4320a54c3b4552ddc84b",
      "c4ac762c9c004b1a9badeaace27a9cdb",
      "930405bbf7e64e0684d32ddeccf447a9",
      "7a52151811ab4fbf87fbea68f86f0941",
      "16a587a7fe9248b29b89a251b236b654",
      "45f3528733694da4869777af9b9f34a5",
      "bf0d443df21f4b46be7e118fbec29859",
      "1564dc9c52bc4eeca0a819011e3465f0"
     ]
    },
    "id": "3FVLr33NlAAY",
    "outputId": "3b2aad88-faf7-428c-bf24-8e54ca5b0887"
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# model, loss, preds, min_valid_loss, test_rmse = train_model(\n",
    "#     model, X, Y, learning_rate, output_steps = output_steps, batch_size = 64,\n",
    "#     train_idx = train_idx, valid_idx = valid_idx, test_idx = test_idx, test=True)\n",
    "\n",
    "# print({\n",
    "#     'learning_rate': learning_rate,\n",
    "#     'dropout_rate': dropout_rate,\n",
    "#     'num_layers':num_layers,\n",
    "#     'hidden_dim': hidden_dim,\n",
    "# #     'model_state_dict': model.state_dict(),\n",
    "# #     'loss': loss,\n",
    "#     'min_valid_loss': min_valid_loss,\n",
    "# #     'preds':preds,\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ml73nc914po7",
    "outputId": "aa72874e-c060-4057-da46-0c85d6406659"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (lstm): LSTM(1, 64, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (lstm): LSTM(1, 128, batch_first=True, dropout=0.2)\n",
       "    (out): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_path = r'C:\\Users\\rmartinez4\\Box\\Personal Git\\Nautilus-seq2seq\\dataaccess_station_400001\\traffic_bayArea_station_400001_model.pth'\n",
    "# model_path = r'C:\\Users\\rmartinez4\\Box\\Personal Git\\Nautilus-seq2seq\\scratch\\model_outputs\\dataaccess_mediumSize_50station\\traffic_bayArea_station_mediumSize_12pts_model.pth'\n",
    "# model_path = r'C:\\Users\\rmartinez4\\Box\\Personal Git\\Nautilus-seq2seq\\multiple_batch_size\\model_outputs\\128\\station_400001\\trained_model.pth'\n",
    "\n",
    "model_path = r'C:\\Users\\rmartinez4\\Box\\Personal Git\\Nautilus-seq2seq\\seq2seq-find-MAE-value\\trained_model_0.0001_0.2_64.pth'\n",
    "\n",
    "encoder = Encoder(input_size, hidden_dim, num_layers, dropout_rate)\n",
    "decoder = Decoder(output_size, hidden_dim, num_layers, dropout_rate)\n",
    "\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # load state dict\n",
    "# model_dict = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "# model.load_state_dict(model_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 24.5 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# load model object\n",
    "model_obj = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "model.load_state_dict(model_obj.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['encoder.lstm.weight_ih_l0', 'encoder.lstm.weight_hh_l0', 'encoder.lstm.bias_ih_l0', 'encoder.lstm.bias_hh_l0', 'encoder.lstm.weight_ih_l0_reverse', 'encoder.lstm.weight_hh_l0_reverse', 'encoder.lstm.bias_ih_l0_reverse', 'encoder.lstm.bias_hh_l0_reverse', 'decoder.lstm.weight_ih_l0', 'decoder.lstm.weight_hh_l0', 'decoder.lstm.bias_ih_l0', 'decoder.lstm.bias_hh_l0', 'decoder.out.weight', 'decoder.out.bias'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_obj.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.1'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (lstm): LSTM(1, 64, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (lstm): LSTM(1, 128, batch_first=True, dropout=0.2)\n",
       "    (out): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 42min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# make sure to update batch size\n",
    "\n",
    "test_rmse, test_set = [], Dataset(X, Y, test_idx, output_steps)\n",
    "test_generator = data.DataLoader(test_set, batch_size = 512, shuffle = False)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "model.eval()\n",
    "t_rmse, preds = run_epoch_eval(model, test_generator, criterion, return_pred = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8309140"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rmse, train_set = [], Dataset(X, Y, train_idx, output_steps)\n",
    "train_generator = data.DataLoader(train_set, batch_size = 512, shuffle = False)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "model.eval()\n",
    "t_rmse_train, preds_train = run_epoch_eval(model, train_generator, criterion, return_pred = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8309140, 12)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4597"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4154570, 12)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4154570, 12, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.reshape(torch.tensor(preds), (4154570, 12, 1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = c_time_series[:training_size,pred_size:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_mae_loss(y_pred, y_true):\n",
    "    mask = (y_true != 0).float()\n",
    "    mask /= mask.mean()\n",
    "    loss = torch.abs(y_pred - y_true)\n",
    "    loss = loss * mask\n",
    "    # trick for nans: https://discuss.pytorch.org/t/how-to-set-nan-in-tensor-to-0/3918/3\n",
    "    loss[loss != loss] = 0\n",
    "    return loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999997524875"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.375810849192396e-13"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.9402, dtype=torch.float64)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = Y_test\n",
    "y_pred = torch.reshape(torch.tensor(preds), (4154570, 12, 1))*float(c_time_series.std()) + float(c_time_series.mean())\n",
    "\n",
    "masked_mae_loss(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5686, dtype=torch.float64)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = c_time_series[:training_size,pred_size:,:]\n",
    "y_pred = torch.reshape(torch.tensor(preds_train), (8309140, 12, 1))*float(c_time_series.std()) + float(c_time_series.mean())\n",
    "\n",
    "masked_mae_loss(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Gcolab_seq2seq_traffic_Data.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "199.006px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1564dc9c52bc4eeca0a819011e3465f0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "16a587a7fe9248b29b89a251b236b654": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "45f3528733694da4869777af9b9f34a5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7a52151811ab4fbf87fbea68f86f0941": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1564dc9c52bc4eeca0a819011e3465f0",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_bf0d443df21f4b46be7e118fbec29859",
      "value": " 27/200 [1:06:42&lt;6:50:39, 142.43s/it]"
     }
    },
    "86efb748af4d4320a54c3b4552ddc84b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_930405bbf7e64e0684d32ddeccf447a9",
       "IPY_MODEL_7a52151811ab4fbf87fbea68f86f0941"
      ],
      "layout": "IPY_MODEL_c4ac762c9c004b1a9badeaace27a9cdb"
     }
    },
    "930405bbf7e64e0684d32ddeccf447a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": " 14%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_45f3528733694da4869777af9b9f34a5",
      "max": 200,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_16a587a7fe9248b29b89a251b236b654",
      "value": 27
     }
    },
    "bf0d443df21f4b46be7e118fbec29859": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c4ac762c9c004b1a9badeaace27a9cdb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
